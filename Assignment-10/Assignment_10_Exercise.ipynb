{"cells":[{"cell_type":"markdown","metadata":{"id":"zmwWs4S9cRIn"},"source":["# ECE 570 Assignment 10 Exercise\n","\n","\n","\n","\n","\n","\n","Your Name:"]},{"cell_type":"markdown","metadata":{"id":"Zz2T0QYYpwVR"},"source":["## Exercise 1: Creating an image denoiser using a CNN autoencoder (20 points).\n","In this exercise you are trying to build an autoencoder with CNN layers that can denoise images.\n","\n","### Task 1: Create additive noise transform\n","Add code to `AddGaussianNoise` transform class that will:\n","  * Add additive Gaussian noise to the batch of input images (i.e add noise with gaussian distribution on each pixel). The noise for every pixel should have mean value 0 and standard deviation of 0.3, i.e $ \\epsilon \\sim N(0, 0.3)$.\n","  * Clip the values to be between 0 and 1 again as they may be outside the range for pixel values after adding Gaussian noise.\n","  * Make sure that the Gaussian noise added each time is different. Gaussian noise added to one image should not be same as the noise added to another image.\n","  \n","We provide code to plot the first 3 training images and their noisy counterparts in a 2x3 subplot.\n","We also provide code that concatenates the original dataset and noisy dataset to get a single dataloader. In general, you should be careful with what you load at each iteration. In a more general case, there are many ways of dealing with multiple datasets. For example, you can create separate dataloaders and use ``zip`` to load samples from them. Here is a post discussing how to use ``zip`` [https://discuss.pytorch.org/t/two-dataloaders-from-two-different-datasets-within-the-same-loop/87766/1](https://discuss.pytorch.org/t/two-dataloaders-from-two-different-datasets-within-the-same-loop/87766/1)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTo6hwMo-6Ai"},"outputs":[],"source":["# Import and load MNIST data\n","import torchvision\n","import torch\n","import matplotlib.pyplot as plt\n","\n","class AddGaussianNoise(object):\n","  ###########################   <YOUR CODE>  ############################\n","  # Implement the AddGaussianNoise class\n","\n","\n","  #########################  <END YOUR CODE>  ############################\n","\n","transform_noisy = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), AddGaussianNoise(0.,0.3)])\n","transform_original = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n","\n","train_dataset_noisy = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform_noisy)\n","train_dataset_original = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform_original)\n","test_dataset_noisy = torchvision.datasets.MNIST('data', train=False, download=True, transform=transform_noisy)\n","test_dataset_original = torchvision.datasets.MNIST('data', train=False, download=True, transform=transform_original)\n","\n","print(torch.max(train_dataset_noisy.__getitem__(0)[0]).item())\n","print(torch.min(train_dataset_noisy.__getitem__(0)[0]).item())\n","\n","noise_0 = train_dataset_noisy.__getitem__(0)[0] - train_dataset_original.__getitem__(0)[0]\n","noise_1 = train_dataset_noisy.__getitem__(1)[0] - train_dataset_original.__getitem__(1)[0]\n","print(f'Is added noise different in different images? {not torch.allclose(noise_0, noise_1)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aVGreIhv8WKh"},"outputs":[],"source":["class ConcatDataset(torch.utils.data.Dataset):\n","  def __init__(self, *datasets):\n","    self.datasets = datasets\n","\n","  def __getitem__(self, i):\n","    return tuple(d[i][0] for d in self.datasets)\n","\n","  def __len__(self):\n","    return min(len(d) for d in self.datasets)\n","\n","\n","batch_size_train, batch_size_test = 64, 1000\n","train_loader = torch.utils.data.DataLoader(ConcatDataset(train_dataset_noisy, train_dataset_original),\n","                      batch_size=batch_size_train, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(ConcatDataset(test_dataset_noisy, test_dataset_original),\n","                      batch_size=batch_size_test, shuffle=False)\n","\n","# Plot the first 3 training images with corresponding noisy images\n","_, (noisy, image) = next(enumerate(train_loader))\n","\n","fig,ax = plt.subplots(2,3)\n","fig.set_size_inches(12,8)\n","for idx in range(3):\n","  ax[0,idx].imshow(noisy[idx][0], cmap='gray')\n","  ax[1,idx].imshow(image[idx][0], cmap='gray')\n","fig.show()\n","\n","device = 'cuda' if torch.cuda.is_available()==True else 'cpu'\n","device = torch.device(device)"]},{"cell_type":"markdown","metadata":{"id":"DFKqew7r-E-q"},"source":["### Task 2: Create and train a denoising autoencoder\n","\n","Build an autoencoder neural network by filling in `__init__` and `forward`. Remember that `__init__` defines the layers or building blocks while `forward` implements the model computation that *implicitly* defines the model structure. This should be more complicated (more params, different layers, combination of CNNs/FCs) than in the instructions. Hint: You may want to create the network to have convolutional and transpose convolutional layers (see `ConvTranspose2D` function in PyTorch documentation).\n","\n","We provide code for the following which you should run to validate your module.\n","1. Move your model to GPU so that you can train your model with GPU.\n","2. Train your denoising autoencoder model with appropriate optimizer and **MSE** loss function. The loss function should be computed between the output of the noisy images and the clean images, i.e., $L(x, g(f(\\tilde{x})))$, where $\\tilde{x} = x + \\epsilon$ is the noisy image and $\\epsilon$ is the Gaussian niose. You should train your model with enough epochs so that your loss reaches a relatively steady value. **Note: Your loss on the test data should be lower than 20.** You may have to experiment with various model architectures to achieve this test loss.\n","3. Visualize your result with a 3 x 3 grid of subplots. You should show 3 test images, 3 test images with noise added, and 3 test images reconstructed after passing your noisy test images through the DAE."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIVO5T4JgA_N"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class our_DAE(nn.Module): # CNN version\n","  def __init__(self):\n","    super(our_DAE, self).__init__()\n","\n","    ###########################   <YOUR CODE>  ############################\n","    # encoder\n","\n","    # decoder\n","\n","    #########################  <END YOUR CODE>  ############################\n","\n","  def forward(self, x):\n","    ###########################   <YOUR CODE>  ############################\n","\n","\n","\n","    #########################  <END YOUR CODE>  ############################\n","\n","DAE = our_DAE().to(device)\n","optimizer = optim.Adam(DAE.parameters(), lr=2e-4)\n","loss_fn = nn.MSELoss(reduction='sum')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSHaggL0ik2Y"},"outputs":[],"source":["# Training and testing code\n","def train(epoch, device):\n","\n","  DAE.train() # we need to set the mode for our model\n","\n","  for batch_idx, (noisy, images) in enumerate(train_loader): # Note that we do not need the labels\n","\n","    optimizer.zero_grad()\n","    noisy, images = noisy.to(device), images.to(device)\n","    output = DAE(noisy)\n","    loss = loss_fn(output, images) # Here is a typical loss function (Mean square error)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch_idx % 10 == 0: # We record our output every 10 batches\n","      train_losses.append(loss.item()/batch_size_train) # item() is to get the value of the tensor directly\n","      train_counter.append(\n","        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n","    if batch_idx % 500 == 0: # We visulize our output every 100 batches\n","      print(f'Epoch {epoch}: [{batch_idx*len(images)}/{len(train_loader.dataset)}] Loss: {loss.item()/batch_size_train}')\n","\n","\n","def test(epoch, device):\n","\n","  DAE.eval() # we need to set the mode for our model\n","\n","  test_loss = 0\n","  correct = 0\n","\n","  with torch.no_grad():\n","    for (noisy, images) in test_loader:\n","      noisy, images = noisy.to(device), images.to(device)\n","      output = DAE(noisy)\n","      test_loss += loss_fn(output, images).item()\n","\n","  test_loss /= len(test_loader.dataset)\n","  test_losses.append(test_loss)\n","  test_counter.append(len(train_loader.dataset)*epoch)\n","\n","  print(f'Test result on epoch {epoch}: Avg loss is {test_loss}')\n","\n","train_losses = []\n","train_counter = []\n","test_losses = []\n","test_counter = []\n","max_epoch = 5\n","for epoch in range(1, max_epoch+1):\n","  train(epoch, device=device)\n","  test(epoch, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FvuRNLCukBWX"},"outputs":[],"source":["# Visualization code\n","import matplotlib.pyplot as plt\n","\n","_, (noisy, images) = next(enumerate(test_loader))\n","noisy, images = noisy.to(device), images.to(device)\n","output = DAE(noisy).cpu().detach()\n","noisy, images = noisy.cpu(), images.cpu()\n","\n","print(images.size(), output.size())\n","\n","fig, ax = plt.subplots(3,3)\n","fig.set_size_inches(12,6)\n","\n","for idx in range(3):\n","  ax[0,idx].imshow(images[idx][0], cmap='gray')\n","  ax[1,idx].imshow(noisy[idx][0], cmap='gray')\n","  ax[2,idx].imshow(output[idx][0], cmap='gray')\n","\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"290mOBEHgEXr"},"source":["## Exercise 2: Build a variational autoencoder (VAE) that can generate MNIST images (60 points)\n","\n","We provide boilerplate code to do the following:\n","1. Import necessary packages\n","2. Load the MNIST data as above.\n","3. Specify the device."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xd8vWof8nIHw"},"outputs":[],"source":["import torchvision\n","import torch\n","\n","transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()]) # Images already in [0,1]\n","\n","train_dataset = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.MNIST('data', train=False, download=True, transform=transform)\n","\n","batch_size_train, batch_size_test = 64, 1000\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)\n","\n","device = 'cuda' if torch.cuda.is_available()==True else 'cpu'\n","device = torch.device(device)\n","\n","print(f'We are using device name \"{device}\"')"]},{"cell_type":"markdown","metadata":{"id":"oYskA84daTnl"},"source":["### Task 1: VAE Loss function\n","Construct your loss function. The loss function for VAE is a little bit difficult:\n","$$\n","\\begin{aligned}\n","\\textbf{NegativeELBO}(x, g, f) &= \\mathbb{E}_{q_f}[-\\log p_g(x|z)] + KL(q_f(z|x), p_g(z))\\\\\n"," &= \\text{ReconstructionLoss} + \\text{Regularizer}\n","\\end{aligned}\n","$$\n","In this exercise, you will build a VAE (variational autoencoder) given the following assumptions, which simplify the computation of loss function:\n","1. $p_g(z)$ is a standard normal distribution.\n","2. $q_f(z|x)$ is a multivariate Gaussian with trainable mean and variance for each dimension independently.\n","3. The output distribution of the decoder $p_g(x|z)$ is an independent Bernoulli distribution for every pixel value, i.e., the output of the network is a probability value between 0 and 1 that defines the parameter of the Bernoulli distribution. (more details below)\n","\n","For the reconstruction error, while we discussed the Gaussian distribution in class, here we assume the output distribution of the decoder is an independent Bernoulli distribution for every pixel value.\n","The value of the pixel corresponds to the average of the Bernoulli distribution.\n","This loss can be seen in Appendix C.1 of the original VAE paper: https://arxiv.org/pdf/1312.6114.pdf.\n","With this assumption, the reconstruction loss can be calculated using the binary-cross-entropy loss between the original images and the output of the VAE.\n","See [torch.nn.functional.binary_cross_entropy](https://pytorch.org/docs/stable/generated/torch.nn.functional.binary_cross_entropy.html#torch.nn.functional.binary_cross_entropy).\n","You should use the sum reduction of the loss to sum the loss over all the pixels.\n","\n","The second part is the KL-Divergence between your model's approximate posterier $q_f(z|x)$ and the model prior $p_g(z)$.\n","If we assume $p_g(z)$ is a standard normal distribution and $q_f(z|x)$ is a Gaussian with mean $\\mu_j$ and variance $\\sigma_j^2$, then this KL divergence can be computed in closed form (see Appendix B of original VAE paper above for the derivation and proof):\n","\n","$$KL(q_f(z|x), p_g(z)) = -\\frac{1}{2}\\sum_{j=1}^d(1+\\log(\\sigma_j^2)-\\mu_j^2-\\sigma_j^2). $$\n","\n","\n","Your task here is to write a function `vae_loss` which takes as input:\n","1. `output` - The output of your model, i.e., the bernoulli parameter for each pixel, which is needed for the reconstruction term.\n","2. `mu`, `log_var` - The encoder mean and log variance which are needed for the KL term. Note it is easier to output the log of the variance, i.e., $\\log(\\sigma_j^2)$ instead of variance as log variance can be any real number while variance must be positive.\n","3. `images` - The original images needed for the reconstruction term.\n","\n","and returns the  reconstruction loss and the KL loss terms **separately** (i.e., the function should return two loss arrays). To visualize these losses separately in a later task, you will need the reconstruction loss and KL loss separated."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHShuMq5dJOE"},"outputs":[],"source":["def vae_loss(output, mu, log_var, images):\n","  \"\"\"\n","  :param output: this the output of your neural network\n","  :param mu: this is the mu from the latent space\n","  :param log_var: this is the log_var from the latent space\n","  :param images: this is the original sets of images\n","  \"\"\"\n","  ###########################   <YOUR CODE>  ############################\n","  # Calculate the loss\n","\n","  #########################  <END YOUR CODE>  ############################\n"]},{"cell_type":"markdown","metadata":{"id":"KtRaZjtp-pEM"},"source":["### Task 2: VAE model\n","Build the VAE (variational autoencoder) model based on the instructions given below and in the comments.\n","\n","* Inside the `reparameterize` function you job is to output a latent vector. You should first calculate the standard deviation `std` from the log variance variable `log_var` (i.e., compute $\\sigma$ from $\\log (\\sigma^2)$), then generate a random vector from the Gaussian distribution with a mean of `mu` and standard deviation of `std`.  **Importantly**, this should use the reparametrization trick so that we can backpropagate through this random step. Hint: First, generate a random Gaussian vector from a standard normal distribution and then shift and scale based on `mu` and `std` to create the final sample.\n","\n","* Inside the `encoder` function, you should compute a `mu` and `log_var` that both have the shape of `(batch_size, latent_feature)`. One way to do this is a NN that transforms samples from the original dimension to 2x latent dimension, i.e., output a tensor of shape `(batch_size, 2*latent_feature)`.  Then, you will need to split this into two tensors of size `(batch_size, latent_feature)`. Note that both mean and the log variance can be any real number so you do not need to constrain the output in any way."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-BxB-qYBWQv"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class our_VAE(nn.Module):\n","  def __init__(self, latent_feature = 16): # you can use any number of latent features you want in the training\n","    super(our_VAE, self).__init__()\n","\n","    self.latent_feature = latent_feature\n","\n","    ###########################   <YOUR CODE>  ############################\n","    # define the transformations for your encoder and decoder\n","\n","    # encoder\n","\n","    # decoder\n","\n","    #########################  <END YOUR CODE>  ############################\n","\n","  def reparameterize(self, mu, log_var):\n","    \"\"\"\n","    :param mu: mean from the latent space\n","    :param log_var: the log variance from the latent space\n","\n","    You should return a sample with gaussian distribution N(mu, var) using\n","    the reparameterization trick.\n","    \"\"\"\n","    ###########################   <YOUR CODE>  ############################\n","\n","\n","    #########################  <END YOUR CODE>  ############################\n","    return sample\n","\n","  def encoder(self, x):\n","    \"\"\"\n","    :param x: input distribution\n","\n","    You should first compute the parameters mu and log_var for Gaussian distribution q(z|x), and\n","    then get samples from q(z|x) using the reparameterize function you just created.\n","    The final output should include mu, log_var and z ~ q(z|x).\n","    \"\"\"\n","    ###########################   <YOUR CODE>  ############################\n","\n","\n","    #########################  <END YOUR CODE>  ###########################\n","\n","    return mu, log_var, z\n","\n","  def decoder(self, z):\n","    \"\"\"\n","    :param z: latent distribution\n","\n","    You should compute the output x given latent samples z\n","    \"\"\"\n","\n","    ###########################   <YOUR CODE>  ############################\n","\n","    #########################  <END YOUR CODE>  ###########################\n","    return x\n","\n","\n","\n","  def forward(self, x):\n","    \"\"\"\n","    :param x: input variables\n","\n","    You should compute the output images using the encoder and decoder you just defined.\n","    Remember to return the mu and log_var for the computation of loss.\n","    \"\"\"\n","\n","    ###########################   <YOUR CODE>  ############################\n","\n","\n","    #########################  <END YOUR CODE>  ###########################\n","\n","\n","    return x, mu, log_var"]},{"cell_type":"code","source":["# Check reparameterize method by generating samples\n","mu_ = [-1.0, 0, 1.0]\n","var_ = [0.1, 0.2, 0.3]\n","vae = our_VAE()\n","\n","torch.manual_seed(42)\n","for i, (m,v) in enumerate(zip(mu_, var_)):\n","    m_t = torch.Tensor([m])\n","    v_t = torch.Tensor([v])\n","    samples = torch.cat([vae.reparameterize(m_t, torch.log(v_t)) for _ in range(10000)])\n","    mean = torch.mean(samples)\n","    var = torch.var(samples)\n","    print(f'###### Test Case {i+1}: mu = {m}, var = {v} ######')\n","    print(f'Is mean of the samples close to the actual mean? {torch.allclose(mean, m_t, atol=1e-2)}') # True\n","    print(f'Is variance of the samples close to the actual variance? {torch.allclose(var, v_t, atol=1e-2)}\\n') # True"],"metadata":{"id":"GJpkjoEZYjX7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vvSUZtwcd4jx"},"source":["### Task 3: Train and validate your model\n","We now provide code to do the following that you must run to validate your code (you may need to increase the number of max epochs):\n","\n","1. Train your model with an appropriate optimizer and the above loss function. You should train your model with enough epochs so that your loss reaches a relatively steady value.\n","\n","2. Visualize your result. You should **show three pairs of images** where each pair consists of an original test image and its VAE reconstructed version.\n","\n","3. Keep track of the loss. You should save the negative ELBO, Reconstruction Loss and KL Divergence Loss after every 10 batches in the trainining and **create a plot with three curves** using [matplotlib.pyplot.plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html). Each curve should correpond to one of the losses. The x-axis will be the number of batches divided by 10 and the y-axis will be the loss. **Make sure you clearly specify the legend, title, x-label and y-label.**\n","\n","**Note:** It is always a good idea to keep track of the loss in the process of training to help you understand what is happening during training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKHOYLYldYC7"},"outputs":[],"source":["# Training code\n","def train(epoch, device, quiet=False):\n","\n","  VAE.train() # we need to set the mode for our model\n","\n","  for batch_idx, (images, _) in enumerate(train_loader): # Note that we do not need the labels\n","\n","    optimizer.zero_grad()\n","    output, mu, log_var = VAE(images)\n","    bce, kld = vae_loss(output, mu, log_var, images) # Here is a typical loss function (Mean square error)\n","    loss = bce + kld\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch_idx % 10 == 0: # We record our output every 10 batches\n","      bce_losses.append(bce/batch_size_train)\n","      kld_losses.append(kld/batch_size_train)\n","      train_losses.append(loss.item()/batch_size_train) # item() is to get the value of the tensor directly\n","      train_counter.append(\n","        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n","    if batch_idx % 100 == 0 and not quiet: # We visulize our output every 100 batches\n","      print(f'Epoch {epoch}: [{batch_idx*len(images)}/{len(train_loader.dataset)}] Loss: {loss.item()/batch_size_train}')\n","\n","# Testing code\n","def test(epoch, device, quiet=False):\n","\n","  VAE.eval() # we need to set the mode for our model\n","\n","  test_loss = 0\n","  correct = 0\n","\n","  with torch.no_grad():\n","    for images, _ in test_loader:\n","      output, mu, log_var = VAE(images)\n","      bce, kld = vae_loss(output, mu, log_var, images)\n","      test_loss += bce+kld\n","  test_loss /= len(test_loader.dataset)\n","  test_losses.append(test_loss)\n","  test_counter.append(len(train_loader.dataset)*epoch)\n","\n","  if not quiet:\n","    print(f'Test result on epoch {epoch}: Avg loss is {test_loss}')\n","\n","# Running train and test\n","import torch.optim as optim\n","\n","VAE = our_VAE()\n","optimizer = optim.Adam(VAE.parameters(), lr=1e-4)\n","\n","train_losses = []\n","train_counter = []\n","bce_losses = []\n","kld_losses = []\n","test_losses = []\n","test_counter = []\n","max_epoch = 3\n","\n","for epoch in range(1, max_epoch+1):\n","  train(epoch, device=device)\n","  test(epoch, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hS1x7sKCcHBy"},"outputs":[],"source":["# Visualization code\n","import matplotlib.pyplot as plt\n","\n","batch_idx, (images, _) = next(enumerate(test_loader))\n","output = VAE(images)[0].detach()\n","images = images.cpu()\n","\n","\n","fig, ax = plt.subplots(2,4)\n","fig.set_size_inches(12,6)\n","\n","for idx in range(4):\n","  ax[0,idx].imshow(images[idx][0], cmap='gray')\n","  ax[1,idx].imshow(output[idx][0], cmap='gray')\n","\n","fig.show()\n","\n","plt.figure()\n","plt.plot(train_losses,label = '- elbo')\n","plt.plot([i.item() for i in bce_losses],label = 'recon')\n","plt.plot([i.item() for i in kld_losses],label = 'kl')\n","plt.xlabel('iterations')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"uzgIFsux2wu3"},"source":["# Exercise 3: Exploring the latent space of VAE (20 points)\n","\n","### Task 1: Latent space of VAE"]},{"cell_type":"markdown","metadata":{"id":"ojuYyCpvVjeV"},"source":["The latent space will change over time during training as the networks learn which features of the input are most important.  In the beginning, the reconstruction error will be poor and the latent space will be mixed up (i.e., it has not identified good features for dimensionality reduction and then reconstruction).  However, as it continues to train, the space will begin to show some structure (similar to in PCA) as it finds features that enable good reconstruction even after adding a little noise. Therefore, to get some intuition about this process, in this task, you will visualize how latent space changes in the process of training. We provide the function ``plot_latent`` to simplify your exploration.\n","\n","1. For better visualization, create a VAE with ``latent_features=2``.\n","2. Similar to task 3, train the VAE for 10 epochs. But you will need to plot the latent distribution using the provided ``plot_latent`` function below at initialization **before training** (so you can see what the latent space looks like at initialization) AND after the 5th and 10th epoch. You should use the **test** data for plotting this visualization task. With the correct training you will see some clusters in the latent space after some epochs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mojv6PtOVwKy"},"outputs":[],"source":["def plot_latent(vae, data_loader, num_batches=2):\n","  with torch.no_grad():\n","    for ibx, (images,label) in enumerate(data_loader):\n","      _,_,z = vae.encoder(images)\n","      z = z.to('cpu').detach().numpy()\n","      plt.scatter(z[:, 0], z[:, 1], c=label, cmap='tab10',s=1)\n","      if ibx > num_batches:\n","        break\n","  plt.colorbar()\n","  plt.show()\n","\n","import torch.optim as optim\n","\n","VAE = our_VAE(latent_feature=2)\n","optimizer = optim.Adam(VAE.parameters(), lr=1e-4)\n","\n","train_losses = []\n","train_counter = []\n","bce_losses = []\n","kld_losses = []\n","test_losses = []\n","test_counter = []\n","max_epoch = 10\n","###########################   <YOUR CODE>  ############################\n","# plot the latent space before training\n","# plot the latent space after training 5 epochs and 10 epochs\n","\n","\n","\n","#########################  <END YOUR CODE>  ###########################"]},{"cell_type":"markdown","metadata":{"id":"6t8USlTaWuyH"},"source":["### Task 2 Interpolation of latent space\n","\n","Interpolation can be quite useful for autoencoder models. For example, by linearly interpolating (or mixing) codes in latent space and decoding the result, the autoencoder can produce a more **semantically meaningful**\n","combination of the corresponding datapoints than linear interpolation in the raw pixel space.\n","Besides, in some cases, interpolation experiments can show that the model has learned a latent space with a particular structure. Specifically, if interpolation between points in the latent space shows a smooth semantic warping in the original image space, then the visualization may suggest that similar points are semantically clustered in the latent space.\n","\n","In this task, you will do a simple experiment to see the difference between linear interpolation in the latent space and the original data space (raw pixels). We have already selected two latent images from the test set `z0` and `z1` and their corresponding reconstructions `x0` and `x1` that correspond to a 1 and an 8 digit respectively.\n","Given this setup, your task is to do the following:\n","\n","1. Compute the linear interpolation of $x_0$ and $x_1$ in the following way: $x'=\\alpha x_1 + (1-\\alpha)x_0$ where $\\alpha = 0, 0.1, 0.2, \\dots, 0.9, 1.0$, i.e., 11 points between 0 and 1. It is recommended to use broadcasting (possibly with reshaping) to create these without a loop.\n","\n","2. Compute the **latent** linear interpolation of $z_0$ and $z_1$ to get $z'$ in a similar way. Then, reconstruct the $x'$ corresponding to each $z'$ using the VAE decoder.\n","\n","We provide code to select initial examples and plot the visualization of the interpolations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qui9L8O9YTSt"},"outputs":[],"source":["def linear_interpolation(x0, x1):\n","  ###########################   <YOUR CODE>  ############################\n","  # The output of x_interp should be a tensor that has shape (11, 1, 28, 28)\n","\n","  #########################  <END YOUR CODE>  ###########################\n","  return x_interp\n","\n","def latent_linear_interpolation(z0, z1, VAE):\n","  ###########################   <YOUR CODE>  ############################\n","  # The output of x_latent_interp should be a tensor that has shape (11, 1, 28, 28)\n","  # Note that first you will need to interpolate between z0 and z1\n","  #  then you will need to decode these z's via the VAE decoder to get\n","  #  reconstructed images in the image space.\n","\n","\n","  #########################  <END YOUR CODE>  ###########################\n","  return x_interp_latent\n","\n","import numpy as np\n","with torch.no_grad():\n","  images,label = next(enumerate(test_loader))[1]\n","  #print(images.shape)\n","  _,_,z = VAE.encoder(images)\n","  z = z.to('cpu').detach().numpy()\n","  z0 = z[label==1][0]\n","  z1 = z[label==8][0]\n","  x0 = VAE.decoder(torch.Tensor(z0))\n","  x1 = VAE.decoder(torch.Tensor(z1))\n","\n","  # Visualize linear interpolation in x space\n","  xp = linear_interpolation(x0, x1)\n","  grid_img = torchvision.utils.make_grid(xp, nrow=11)\n","  plt.imshow(grid_img.permute(1, 2, 0))\n","  plt.show()\n","\n","  # Visualize latent linear interpolation in z space that has been reconstructed in x space\n","  xzp = latent_linear_interpolation(z0, z1, VAE)\n","  grid_img = torchvision.utils.make_grid(xzp, nrow=11)\n","  plt.imshow(grid_img.permute(1, 2, 0))\n","  plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"38b65d22d35179c6935a22cd0c80ce3ebfa39e2ed4f084b887887c7215100d32"}}},"nbformat":4,"nbformat_minor":0}