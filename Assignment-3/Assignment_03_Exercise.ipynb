{"cells":[{"cell_type":"markdown","metadata":{"id":"kLTpDVQk0ozE"},"source":["# ECE 57000 Assignment 3 Exercises\n","\n","\n","\n","Name:"]},{"cell_type":"markdown","metadata":{"id":"APWN2dfm7fx_"},"source":["# Exercise 0 (Important submission information)\n","\n","1. Follow the instructions in the provided \"uploader.ipynb\" to convert your ipynb file into PDF format.\n","2. Please make sure to select the corresponding pages for each exercise when you submitting your PDF to Gradescope. Make sure to include both the **output** and the **code** when selecting pages. (You do not need to include the instruction for the exercises)\n","3. **Do not change** anything outside of \"YOUR CODE\" block\n","\n","\n","**We may assess a 20% penalty for those who do not correctly follow these steps.**"]},{"cell_type":"markdown","metadata":{"id":"VYEboKWL8LLy"},"source":["## Exercise 1 (20/100 points)\n","\n","In this exercise, you will implement linear regression using the polynomial features and compare results for different choices of degrees for the polynomial visually.\n","\n","### Task 1: Generate the data\n","The data should be a noisy version of a sin wave i.e\n","$y = \\sin (x) + \\epsilon $  where $\\epsilon \\sim \\text{NormalDistribution}(\\mu,\\sigma)$.  Note $\\epsilon$ should be different for every point.\n","\n","1. Generate **50** evenly spaced numbers over the interval $[0,4\\pi]$ and store them as a vector called `X`.\n","2. Generate `y` from `X` by using the equation above with the parameter $\\mu=0, \\sigma=0.1$\n","3. Do a scatter plot on `X` and `y` and give the plot and axis reasonable names/title.\n","\n","(You may want to look over the code in section 2 in the instruction notebook under \"Simple Linear Regression\".)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IVAotrp7Y55Z"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","####################         YOUR CODE         ####################\n","\n","\n","\n","####################         END CODE          ####################\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"yOS4fzs0fEjG"},"source":["### Task 2: Fit the data\n","Now try to use tools in sklearn to fit the data with varying degrees of the polynomial. The general process is:\n","1. Create an estimator based on pipelining the function **PolynomialFeatures(degree)** and **LinearRegression()** (Read the instruction)\n","2. Fit the estimator to the data you created in Task 1. (Note the estimator will expect a 2D array so you may have to reshape `X` where rows correspond to samples and columns correspond to feature(s).)\n","3. Evaluate your trained estimator by using the given vector **xfit**, and plot the result curve over the scatter plot of your data.\n","(The plot should look similar to the plot on the part 1 of the instruction)\n","\n","The output of your code should be a 2 by 2 grid of subplots (see [`plt.subplots`](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.subplots.html) or [`plt.subplot`](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.subplot.html#matplotlib.pyplot.subplot)) where each plot visualizes the mdoel fitted using different polynomial degrees (see above), specifically degrees `[3, 5, 9, 15]` respectively.\n","Each subplot should be given a reasonable title to identify what it represents.\n","\n","NOTE: It is perfectly normal if the graph looks crazy for high degrees of polynomial choice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kmPdZCA0uRl"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import PolynomialFeatures\n","\n","xfit = np.linspace(0, 4*np.pi, 1000)\n","\n","####################         YOUR CODE         ####################\n","\n","\n","\n","\n","####################         END CODE          ####################\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"q6dlKdg0ilkM"},"source":["## Exercise 2: Visualizing KNN classifier on IRIS dataset (30/100 points)\n","In this exercise, you will use KNN classifier to do simple classification on [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)."]},{"cell_type":"markdown","metadata":{"id":"jqvoJp1lioPE"},"source":["### Task 1: Load the Iris dataset\n","Iris dataset can be simply loaded by calling the function [`datasets.load_iris()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris).\n","Use the official documentation for this function to create variables that stores the following information:\n","1.  `X`: stores the first two features.\n","2.  `y`: stores all labels.\n","3.  `feature_names`: the meaning for the first two features.\n","4.  `target_names`: the meaning for each label.\n","\n","(You will have to remove some features from the original dataset to get only 2, e.g., slicing by [0:2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBvWFZBnnXtm"},"outputs":[],"source":["from sklearn import datasets\n","\n","####################         YOUR CODE         ####################\n","\n","\n","\n","\n","####################         END CODE          ####################\n","\n","print(f'X has the shape {X.shape}')\n","print(f'y has the shape {y.shape}')\n","print(f'X has features: {feature_names}')\n","print(f'y has labels: {target_names}')"]},{"cell_type":"markdown","metadata":{"id":"D3RCAqS6isaQ"},"source":["### Task 2: Train and visualize KNN classfier\n","1. Setup and train the KNN classifier with K=15. (See instructions)\n","2. See examples [here](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/) and use `plot_decision_regions()` to visualize the decision boundary for trained classifier. Be sure to name the axis with corresponding name of the feature.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XkGjsjpVvzX"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.neighbors import KNeighborsClassifier\n","from mlxtend.plotting import plot_decision_regions\n","\n","####################         YOUR CODE         ####################\n","\n","\n","\n","\n","####################         END CODE          ####################"]},{"cell_type":"markdown","metadata":{"id":"pZ_YHIuBixz9"},"source":["## Exercise 3: KNN classifier on credit fraud dataset (50/100 points)\n","In this exercise, you will use K-nearest-neighbor method to create a model that is able to detect potential credit card fraud.\n","\n","### Task 1: Mount your drive\n","Follow the step on the instructions and mount your google drive on Colab which allows to access the .csv file uploaded on your drive that was included with this assignment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLFvC76d6R6D"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"FIe7xYXUi1b6"},"source":["### Task 2: Load and preprocess datasets\n","In this program we are using a dataset that has the following features:  \n","\n","V1 | V1 | ... | V10 | Amount | Class\n","---|---|---|---|---|---\n","(float)|(float)|(float)|(float)|(float)|(str)\n","\n","The first ten features are the top PCA values for certain transaction information. The reason only PCA values are given is to protect private information.\n","The **Amount** feature is the amount of money in that particular transaction and the **Class** feature contains two classes **safe** and **Fraud**.\n","Each class has 400 examples, your task is to predict the **Class** feature from all the other features, i.e. determine which transactions are fraudulent or not.\n","\n","1. Load the given .csv file to the variable `data`.\n","2. Create `X` from `data` simply by dropping the last column (which will be our `y`) of the pandas dataframe, and create `y` by selecting the last column of the pandas data frame.\n","3. Use `train_test_split` to create the training and test set (`X_train`, `X_test`, `y_train`, `y_test`) with 20% of the data be the test data and set the `random_state` to `0`.\n","4. Fit the appropriate transform functions (i.e., `StandardScalar` and `LabelEncoder`) for input and output from the training dataset and then apply to both the train and test set (`X_train`, `X_test`, `y_train`, `y_test`) similar to the instructions notebook. You cannot include test set when preprocessing the dataset.\n","\n","Read the instruction section 1 about how to use pandas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sKIMALaKaWh-"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","\n","####################         YOUR CODE         ####################\n","\n","\n","\n","####################         END CODE          ####################\n","\n","print(f'X_train has the shape {X_train.shape}')\n","print(f'y_train has the shape {y_train.shape}')\n","print(f'X_test has the shape {X_test.shape}')\n","print(f'y_test has the shape {y_test.shape}')\n","print(f'X_train mean is {np.mean(X_train, axis=0)}')\n","print(f'X_test mean is {np.mean(X_test, axis=0)}')\n","print(f'Sum of X_train mean is {np.sum(np.mean(X_train, axis=0))}')\n","print(f'Standard deviation of X_train is {np.std(X_train)}')\n","print(f'Sum of X_test mean is {np.sum(np.mean(X_test, axis=0))}')\n","print(f'Standard deviation of X_test is {np.std(X_test)}')"]},{"cell_type":"markdown","metadata":{"id":"q5q1eA_ti67M"},"source":["### Task 3: Find the optimal KNN estimator\n","We need to find the optimal parameters of the KNN estimator (the model selection problem) using cross validation, and then provide a final estimate of the model's generalization performance via the test set.\n","1. Do a grid search (using the `GridSearchCV` estimator from scikit-learn) to optimize the following hyperparameters for KNN (use estimator `KNeighborsClassifier`) and name your gridsearch object `KNN_GV`:\n","  * The number of neighbors `n_neighbors` (set `n_neighbors` to be $[1, 3, 5, ..., 21]$)\n","  * Type of weights considered `weights` (at least two options)\n","  * Type of distance considered `metric` (at least two options)\n","See [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) for possible options for those hyperparameters.\n","2. Fit your gridsearch by specifying the number of folds to 5. (Note: Pass only your training dataset into the `fit` function so that the model selection process doesn't see your test dataset.  `GridSearchCV` will take care of doing cross validation on the training dataset.)\n","3. Print your best parameters combo (`best_params_`) attribute of KN and the corresponding score on the train and test set.\n","\n","(Your final model should have **a training accuracy of at least 95%** and **a test accuracy 90%** to get full credit.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPRzH6CuaXWI"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","####################         YOUR CODE         ####################\n","\n","\n","\n","\n","####################         END CODE          ####################\n","\n","print(f'The best parameters are {KNN_GV.best_params_}')\n","print(f'The best accuracy on the training data is {KNN_GV.score(X_train, y_train)}')\n","print(f'The best accuracy on the testing data is {KNN_GV.score(X_test, y_test)}')"]},{"cell_type":"markdown","metadata":{"id":"z_xW0AoPi_NV"},"source":["### Just for fun: Try out different classifiers in scikit-learn to see if you can beat the test set performance of KNN on this dataset\n","(Please do not include this optional activity in your submission to simplify grading.)\n","\n","Prof. Inouye was able to achieve 96% training and 94% testing accuracy using a combination of methods.  Can you do better?\n","\n","There are many other classifiers in scikit-learn.  A really cool example of many standard classifiers can be seen in the following image from the scikit-learn example on comparing classifiers: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html:\n","\n","<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png\" />\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}